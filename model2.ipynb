{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kritkorn is loading Glove\n",
      "Kritkorn finished loading Glove\n"
     ]
    }
   ],
   "source": [
    "from word2Vec import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../models/research/slim/')\n",
    "from datasets import imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "names = imagenet.create_readable_names_for_imagenet_labels()\n",
    "\n",
    "def accuracy(threshold, testing_wnid='n02893608'):\n",
    "    with open(\"available_hop2.txt\",\"r\") as testing_synsets:\n",
    "        hop2_synset_ids = testing_synsets.read().split()\n",
    "    label_pool = hop2_synset_ids\n",
    "\n",
    "    probs_result_dir = \"/Volumes/Kritkorn/results\"\n",
    "    words_result_dir = '/Volumes/Kritkorn/words'\n",
    "    count_total = 0\n",
    "    count_correct = 0\n",
    "    for probs_file in os.listdir(probs_result_dir):\n",
    "        if not probs_file.startswith(testing_wnid): # buskin\n",
    "            continue\n",
    "    #     print type(-probability_distribution)\n",
    "        probability_distribution = np.loadtxt(os.path.join(probs_result_dir, probs_file))\n",
    "\n",
    "    #     sorted_inds = [ind[0] for ind in sorted(enumerate(-probability_distribution), key=lambda x:x[1])]\n",
    "    #     top_count = 5\n",
    "    #     print('\\nTop %d for %s' % (top_count, probs_file))\n",
    "    #     for k in range(top_count):\n",
    "    #         index = sorted_inds[k]\n",
    "    #         print('Probability %0.2f%% => [%s]' % (probability_distribution[index] * 100, names[index]))\n",
    "\n",
    "        probability_distribution = probability_distribution[1:]\n",
    "\n",
    "        nns = nearest_neighbor_with_threshold(probability_distribution, 100, label_pool, threshold)\n",
    "        if nns is None:\n",
    "            continue\n",
    "        nn_ids = [x[0] for x in nns]\n",
    "\n",
    "#         print nn_ids[:5] # print top ids\n",
    "#         print [x[1] for x in nns][:5] # print words\n",
    "\n",
    "        count_total += 1\n",
    "        if testing_wnid in nn_ids:\n",
    "#             print \"%s\\t%d\" % (probs_file, nn_ids.index(testing_wnid)) # print rank\n",
    "            count_correct += 1\n",
    "        if count_total % 100 == 0:\n",
    "            print \"%d %d\" % (count_correct, count_total)\n",
    "    return (count_correct, count_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 100\n",
      "40 200\n",
      "56 300\n",
      "74 400\n",
      "92 500\n",
      "110 600\n",
      "129 700\n",
      "140 800\n",
      "159 900\n",
      "180 1000\n",
      "200 1100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(212, 1158)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 100\n",
      "54 200\n",
      "83 300\n",
      "110 400\n",
      "138 500\n",
      "165 600\n",
      "197 700\n",
      "219 800\n",
      "247 900\n",
      "278 1000\n",
      "307 1100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(324, 1158)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 100\n",
      "55 200\n",
      "85 300\n",
      "111 400\n",
      "139 500\n",
      "166 600\n",
      "199 700\n",
      "218 800\n",
      "247 900\n",
      "273 1000\n",
      "304 1100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(320, 1158)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 69)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2763385146804836,\n",
       " 0.2763385146804836,\n",
       " 0.2763385146804836,\n",
       " 0.2763385146804836,\n",
       " 0.27979274611398963,\n",
       " 0.18393782383419688,\n",
       " 0.18307426597582038,\n",
       " 0.11042402826855123]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 100\n",
      "55 200\n",
      "85 300\n",
      "111 400\n",
      "139 500\n",
      "166 600\n",
      "199 700\n",
      "218 800\n",
      "247 900\n",
      "273 1000\n",
      "304 1100\n",
      "28 100\n",
      "55 200\n",
      "85 300\n",
      "111 400\n",
      "139 500\n",
      "166 600\n",
      "199 700\n",
      "218 800\n",
      "247 900\n",
      "273 1000\n",
      "304 1100\n",
      "28 100\n",
      "55 200\n",
      "85 300\n",
      "111 400\n",
      "139 500\n",
      "166 600\n",
      "199 700\n",
      "218 800\n",
      "247 900\n",
      "273 1000\n",
      "304 1100\n",
      "28 100\n",
      "55 200\n",
      "85 300\n",
      "111 400\n",
      "139 500\n",
      "166 600\n",
      "199 700\n",
      "218 800\n",
      "247 900\n",
      "273 1000\n",
      "304 1100\n",
      "27 100\n",
      "54 200\n",
      "83 300\n",
      "110 400\n",
      "138 500\n",
      "165 600\n",
      "197 700\n",
      "219 800\n",
      "247 900\n",
      "278 1000\n",
      "307 1100\n",
      "19 100\n",
      "41 200\n",
      "58 300\n",
      "77 400\n",
      "96 500\n",
      "114 600\n",
      "132 700\n",
      "143 800\n",
      "161 900\n",
      "181 1000\n",
      "201 1100\n",
      "19 100\n",
      "40 200\n",
      "56 300\n",
      "74 400\n",
      "92 500\n",
      "110 600\n",
      "128 700\n",
      "139 800\n",
      "158 900\n",
      "179 1000\n",
      "199 1100\n",
      "9 100\n",
      "23 200\n",
      "31 300\n",
      "38 400\n",
      "52 500\n",
      "62 600\n",
      "75 700\n",
      "82 800\n",
      "92 900\n",
      "109 1000\n",
      "120 1100\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndJnCdgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a826f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "thresholds = np.arange(-0.8, 0.8, 0.2)\n",
    "accuracies = [accuracy(threshold) for threshold in thresholds]\n",
    "accuracies_value = [1.*x/y for x,y in accuracies]\n",
    "plt.plot(thresholds, accuracies_value)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3853605122052256"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_score(get_vec('broom'), get_vec('grinder'), euclidean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = probability_distribution[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[399,\n",
       " 630,\n",
       " 514,\n",
       " 608,\n",
       " 774,\n",
       " 150,\n",
       " 977,\n",
       " 806,\n",
       " 305,\n",
       " 615,\n",
       " 523,\n",
       " 34,\n",
       " 500,\n",
       " 770,\n",
       " 843,\n",
       " 502,\n",
       " 539,\n",
       " 834,\n",
       " 792,\n",
       " 749,\n",
       " 978,\n",
       " 898,\n",
       " 171,\n",
       " 299,\n",
       " 610,\n",
       " 45,\n",
       " 743,\n",
       " 893,\n",
       " 48,\n",
       " 885,\n",
       " 649,\n",
       " 570,\n",
       " 429,\n",
       " 464,\n",
       " 797,\n",
       " 310,\n",
       " 841,\n",
       " 667,\n",
       " 354,\n",
       " 778,\n",
       " 787,\n",
       " 298,\n",
       " 655,\n",
       " 515,\n",
       " 501,\n",
       " 972,\n",
       " 419,\n",
       " 728,\n",
       " 830,\n",
       " 597,\n",
       " 677,\n",
       " 899,\n",
       " 640,\n",
       " 879,\n",
       " 702,\n",
       " 836,\n",
       " 869,\n",
       " 69,\n",
       " 696,\n",
       " 306,\n",
       " 106,\n",
       " 428,\n",
       " 880,\n",
       " 761,\n",
       " 613,\n",
       " 104,\n",
       " 33,\n",
       " 414,\n",
       " 487,\n",
       " 412,\n",
       " 596,\n",
       " 741,\n",
       " 890,\n",
       " 54,\n",
       " 884,\n",
       " 473,\n",
       " 42,\n",
       " 842,\n",
       " 302,\n",
       " 587,\n",
       " 999,\n",
       " 423,\n",
       " 658,\n",
       " 838,\n",
       " 4,\n",
       " 600,\n",
       " 652,\n",
       " 559,\n",
       " 465,\n",
       " 457,\n",
       " 747,\n",
       " 638,\n",
       " 463,\n",
       " 700,\n",
       " 544,\n",
       " 551,\n",
       " 913,\n",
       " 172,\n",
       " 151,\n",
       " 777,\n",
       " 620,\n",
       " 461,\n",
       " 102,\n",
       " 654,\n",
       " 41,\n",
       " 788,\n",
       " 872,\n",
       " 808,\n",
       " 478,\n",
       " 837,\n",
       " 358,\n",
       " 237,\n",
       " 982,\n",
       " 775,\n",
       " 906,\n",
       " 71,\n",
       " 831,\n",
       " 245,\n",
       " 739,\n",
       " 689,\n",
       " 858,\n",
       " 314,\n",
       " 6,\n",
       " 336,\n",
       " 929,\n",
       " 440,\n",
       " 63,\n",
       " 897,\n",
       " 454,\n",
       " 488,\n",
       " 397,\n",
       " 268,\n",
       " 643,\n",
       " 961,\n",
       " 636,\n",
       " 737,\n",
       " 981,\n",
       " 44,\n",
       " 703,\n",
       " 666,\n",
       " 65,\n",
       " 602,\n",
       " 390,\n",
       " 639,\n",
       " 740,\n",
       " 549,\n",
       " 7,\n",
       " 974,\n",
       " 674,\n",
       " 665,\n",
       " 499,\n",
       " 92,\n",
       " 844,\n",
       " 578,\n",
       " 103,\n",
       " 704,\n",
       " 508,\n",
       " 327,\n",
       " 663,\n",
       " 297,\n",
       " 776,\n",
       " 681,\n",
       " 236,\n",
       " 471,\n",
       " 730,\n",
       " 763,\n",
       " 424,\n",
       " 558,\n",
       " 145,\n",
       " 796,\n",
       " 953,\n",
       " 479,\n",
       " 773,\n",
       " 28,\n",
       " 400,\n",
       " 622,\n",
       " 79,\n",
       " 346,\n",
       " 563,\n",
       " 76,\n",
       " 682,\n",
       " 301,\n",
       " 853,\n",
       " 489,\n",
       " 671,\n",
       " 542,\n",
       " 366,\n",
       " 513,\n",
       " 185,\n",
       " 670,\n",
       " 612,\n",
       " 66,\n",
       " 23,\n",
       " 908,\n",
       " 341,\n",
       " 987,\n",
       " 458,\n",
       " 683,\n",
       " 795,\n",
       " 695,\n",
       " 721,\n",
       " 385,\n",
       " 753,\n",
       " 779,\n",
       " 735,\n",
       " 824,\n",
       " 480,\n",
       " 481,\n",
       " 189,\n",
       " 552,\n",
       " 5,\n",
       " 264,\n",
       " 631,\n",
       " 474,\n",
       " 75,\n",
       " 263,\n",
       " 646,\n",
       " 805,\n",
       " 197,\n",
       " 156,\n",
       " 722,\n",
       " 344,\n",
       " 77,\n",
       " 25,\n",
       " 568,\n",
       " 518,\n",
       " 632,\n",
       " 801,\n",
       " 590,\n",
       " 62,\n",
       " 593,\n",
       " 413,\n",
       " 406,\n",
       " 343,\n",
       " 67,\n",
       " 329,\n",
       " 616,\n",
       " 819,\n",
       " 825,\n",
       " 490,\n",
       " 907,\n",
       " 731,\n",
       " 983,\n",
       " 579,\n",
       " 68,\n",
       " 462,\n",
       " 641,\n",
       " 967,\n",
       " 256,\n",
       " 386,\n",
       " 603,\n",
       " 807,\n",
       " 857,\n",
       " 276,\n",
       " 769,\n",
       " 56,\n",
       " 626,\n",
       " 955,\n",
       " 916,\n",
       " 447,\n",
       " 827,\n",
       " 919,\n",
       " 764,\n",
       " 609,\n",
       " 374,\n",
       " 818,\n",
       " 988,\n",
       " 835,\n",
       " 637,\n",
       " 892,\n",
       " 52,\n",
       " 39,\n",
       " 811,\n",
       " 342,\n",
       " 401,\n",
       " 208,\n",
       " 851,\n",
       " 971,\n",
       " 195,\n",
       " 224,\n",
       " 8,\n",
       " 877,\n",
       " 158,\n",
       " 576,\n",
       " 736,\n",
       " 868,\n",
       " 627,\n",
       " 147,\n",
       " 765,\n",
       " 799,\n",
       " 125,\n",
       " 345,\n",
       " 37,\n",
       " 235,\n",
       " 359,\n",
       " 328,\n",
       " 460,\n",
       " 889,\n",
       " 330,\n",
       " 491,\n",
       " 528,\n",
       " 543,\n",
       " 186,\n",
       " 784,\n",
       " 571,\n",
       " 251,\n",
       " 280,\n",
       " 845,\n",
       " 887,\n",
       " 524,\n",
       " 697,\n",
       " 746,\n",
       " 545,\n",
       " 198,\n",
       " 231,\n",
       " 522,\n",
       " 226,\n",
       " 684,\n",
       " 619,\n",
       " 161,\n",
       " 759,\n",
       " 441,\n",
       " 541,\n",
       " 254,\n",
       " 876,\n",
       " 43,\n",
       " 531,\n",
       " 146,\n",
       " 669,\n",
       " 225,\n",
       " 383,\n",
       " 733,\n",
       " 455,\n",
       " 285,\n",
       " 957,\n",
       " 364,\n",
       " 421,\n",
       " 911,\n",
       " 46,\n",
       " 651,\n",
       " 420,\n",
       " 918,\n",
       " 416,\n",
       " 334,\n",
       " 591,\n",
       " 895,\n",
       " 319,\n",
       " 246,\n",
       " 373,\n",
       " 623,\n",
       " 427,\n",
       " 206,\n",
       " 614,\n",
       " 529,\n",
       " 53,\n",
       " 173,\n",
       " 484,\n",
       " 512,\n",
       " 958,\n",
       " 909,\n",
       " 155,\n",
       " 273,\n",
       " 561,\n",
       " 606,\n",
       " 88,\n",
       " 860,\n",
       " 363,\n",
       " 230,\n",
       " 112,\n",
       " 190,\n",
       " 767,\n",
       " 36,\n",
       " 950,\n",
       " 882,\n",
       " 312,\n",
       " 169,\n",
       " 107,\n",
       " 326,\n",
       " 760,\n",
       " 772,\n",
       " 617,\n",
       " 199,\n",
       " 85,\n",
       " 241,\n",
       " 300,\n",
       " 920,\n",
       " 756,\n",
       " 714,\n",
       " 283,\n",
       " 493,\n",
       " 832,\n",
       " 370,\n",
       " 928,\n",
       " 752,\n",
       " 290,\n",
       " 347,\n",
       " 207,\n",
       " 137,\n",
       " 422,\n",
       " 418,\n",
       " 187,\n",
       " 202,\n",
       " 566,\n",
       " 905,\n",
       " 980,\n",
       " 178,\n",
       " 49,\n",
       " 407,\n",
       " 410,\n",
       " 162,\n",
       " 931,\n",
       " 968,\n",
       " 286,\n",
       " 883,\n",
       " 443,\n",
       " 355,\n",
       " 203,\n",
       " 415,\n",
       " 496,\n",
       " 605,\n",
       " 223,\n",
       " 395,\n",
       " 904,\n",
       " 486,\n",
       " 159,\n",
       " 629,\n",
       " 281,\n",
       " 750,\n",
       " 956,\n",
       " 17,\n",
       " 976,\n",
       " 567,\n",
       " 581,\n",
       " 738,\n",
       " 353,\n",
       " 442,\n",
       " 153,\n",
       " 60,\n",
       " 679,\n",
       " 592,\n",
       " 333,\n",
       " 394,\n",
       " 707,\n",
       " 492,\n",
       " 785,\n",
       " 91,\n",
       " 89,\n",
       " 109,\n",
       " 497,\n",
       " 692,\n",
       " 822,\n",
       " 951,\n",
       " 715,\n",
       " 896,\n",
       " 782,\n",
       " 521,\n",
       " 634,\n",
       " 168,\n",
       " 325,\n",
       " 686,\n",
       " 690,\n",
       " 965,\n",
       " 74,\n",
       " 941,\n",
       " 644,\n",
       " 891,\n",
       " 78,\n",
       " 350,\n",
       " 800,\n",
       " 952,\n",
       " 657,\n",
       " 469,\n",
       " 532,\n",
       " 411,\n",
       " 249,\n",
       " 598,\n",
       " 222,\n",
       " 266,\n",
       " 192,\n",
       " 124,\n",
       " 934,\n",
       " 356,\n",
       " 275,\n",
       " 724,\n",
       " 120,\n",
       " 204,\n",
       " 944,\n",
       " 160,\n",
       " 126,\n",
       " 744,\n",
       " 970,\n",
       " 960,\n",
       " 762,\n",
       " 227,\n",
       " 864,\n",
       " 453,\n",
       " 538,\n",
       " 216,\n",
       " 949,\n",
       " 296,\n",
       " 149,\n",
       " 138,\n",
       " 583,\n",
       " 771,\n",
       " 262,\n",
       " 362,\n",
       " 119,\n",
       " 136,\n",
       " 564,\n",
       " 680,\n",
       " 840,\n",
       " 618,\n",
       " 886,\n",
       " 154,\n",
       " 210,\n",
       " 259,\n",
       " 650,\n",
       " 432,\n",
       " 308,\n",
       " 284,\n",
       " 915,\n",
       " 18,\n",
       " 176,\n",
       " 377,\n",
       " 577,\n",
       " 140,\n",
       " 116,\n",
       " 604,\n",
       " 201,\n",
       " 917,\n",
       " 870,\n",
       " 588,\n",
       " 82,\n",
       " 261,\n",
       " 881,\n",
       " 467,\n",
       " 852,\n",
       " 468,\n",
       " 569,\n",
       " 228,\n",
       " 477,\n",
       " 793,\n",
       " 165,\n",
       " 114,\n",
       " 861,\n",
       " 601,\n",
       " 930,\n",
       " 794,\n",
       " 57,\n",
       " 93,\n",
       " 910,\n",
       " 3,\n",
       " 668,\n",
       " 451,\n",
       " 573,\n",
       " 734,\n",
       " 435,\n",
       " 196,\n",
       " 340,\n",
       " 434,\n",
       " 526,\n",
       " 239,\n",
       " 369,\n",
       " 720,\n",
       " 585,\n",
       " 391,\n",
       " 444,\n",
       " 293,\n",
       " 678,\n",
       " 924,\n",
       " 47,\n",
       " 994,\n",
       " 894,\n",
       " 157,\n",
       " 694,\n",
       " 642,\n",
       " 180,\n",
       " 726,\n",
       " 673,\n",
       " 729,\n",
       " 506,\n",
       " 706,\n",
       " 802,\n",
       " 786,\n",
       " 922,\n",
       " 58,\n",
       " 21,\n",
       " 633,\n",
       " 229,\n",
       " 215,\n",
       " 96,\n",
       " 718,\n",
       " 9,\n",
       " 252,\n",
       " 757,\n",
       " 875,\n",
       " 387,\n",
       " 430,\n",
       " 691,\n",
       " 969,\n",
       " 379,\n",
       " 548,\n",
       " 710,\n",
       " 311,\n",
       " 80,\n",
       " 404,\n",
       " 580,\n",
       " 768,\n",
       " 527,\n",
       " 433,\n",
       " 783,\n",
       " 709,\n",
       " 313,\n",
       " 398,\n",
       " 943,\n",
       " 179,\n",
       " 139,\n",
       " 13,\n",
       " 572,\n",
       " 439,\n",
       " 134,\n",
       " 255,\n",
       " 510,\n",
       " 505,\n",
       " 456,\n",
       " 711,\n",
       " 315,\n",
       " 672,\n",
       " 985,\n",
       " 295,\n",
       " 850,\n",
       " 813,\n",
       " 27,\n",
       " 516,\n",
       " 599,\n",
       " 110,\n",
       " 321,\n",
       " 279,\n",
       " 959,\n",
       " 219,\n",
       " 35,\n",
       " 360,\n",
       " 61,\n",
       " 624,\n",
       " 29,\n",
       " 675,\n",
       " 238,\n",
       " 995,\n",
       " 303,\n",
       " 339,\n",
       " 87,\n",
       " 73,\n",
       " 859,\n",
       " 258,\n",
       " 108,\n",
       " 324,\n",
       " 115,\n",
       " 181,\n",
       " 815,\n",
       " 367,\n",
       " 402,\n",
       " 873,\n",
       " 940,\n",
       " 932,\n",
       " 243,\n",
       " 307,\n",
       " 19,\n",
       " 278,\n",
       " 676,\n",
       " 349,\n",
       " 166,\n",
       " 789,\n",
       " 553,\n",
       " 292,\n",
       " 849,\n",
       " 945,\n",
       " 260,\n",
       " 220,\n",
       " 708,\n",
       " 935,\n",
       " 732,\n",
       " 519,\n",
       " 64,\n",
       " 375,\n",
       " 997,\n",
       " 628,\n",
       " 656,\n",
       " 257,\n",
       " 105,\n",
       " 530,\n",
       " 316,\n",
       " 14,\n",
       " 962,\n",
       " 368,\n",
       " 320,\n",
       " 459,\n",
       " 372,\n",
       " 244,\n",
       " 426,\n",
       " 847,\n",
       " 809,\n",
       " 863,\n",
       " 309,\n",
       " 975,\n",
       " 2,\n",
       " 901,\n",
       " 948,\n",
       " 289,\n",
       " 823,\n",
       " 381,\n",
       " 205,\n",
       " 482,\n",
       " 234,\n",
       " 38,\n",
       " 174,\n",
       " 446,\n",
       " 16,\n",
       " 218,\n",
       " 250,\n",
       " 371,\n",
       " 874,\n",
       " 939,\n",
       " 829,\n",
       " 589,\n",
       " 30,\n",
       " 810,\n",
       " 288,\n",
       " 0,\n",
       " 217,\n",
       " 148,\n",
       " 992,\n",
       " 504,\n",
       " 452,\n",
       " 51,\n",
       " 846,\n",
       " 232,\n",
       " 584,\n",
       " 274,\n",
       " 594,\n",
       " 164,\n",
       " 265,\n",
       " 923,\n",
       " 964,\n",
       " 163,\n",
       " 687,\n",
       " 534,\n",
       " 142,\n",
       " 445,\n",
       " 535,\n",
       " 546,\n",
       " 84,\n",
       " 470,\n",
       " 866,\n",
       " 574,\n",
       " 182,\n",
       " 436,\n",
       " 131,\n",
       " 966,\n",
       " 214,\n",
       " 175,\n",
       " 751,\n",
       " 209,\n",
       " 380,\n",
       " 498,\n",
       " 990,\n",
       " 698,\n",
       " 712,\n",
       " 22,\n",
       " 803,\n",
       " 936,\n",
       " 384,\n",
       " 575,\n",
       " 556,\n",
       " 233,\n",
       " 611,\n",
       " 466,\n",
       " 111,\n",
       " 183,\n",
       " 389,\n",
       " 635,\n",
       " 693,\n",
       " 713,\n",
       " 856,\n",
       " 662,\n",
       " 437,\n",
       " 304,\n",
       " 993,\n",
       " 533,\n",
       " 664,\n",
       " 357,\n",
       " 984,\n",
       " 653,\n",
       " 425,\n",
       " 408,\n",
       " 253,\n",
       " 716,\n",
       " 409,\n",
       " 213,\n",
       " 937,\n",
       " 322,\n",
       " 495,\n",
       " 804,\n",
       " 100,\n",
       " 798,\n",
       " 31,\n",
       " 723,\n",
       " 900,\n",
       " 378,\n",
       " 525,\n",
       " 365,\n",
       " 144,\n",
       " 862,\n",
       " 95,\n",
       " 99,\n",
       " 791,\n",
       " 323,\n",
       " 338,\n",
       " 485,\n",
       " 351,\n",
       " 509,\n",
       " 118,\n",
       " 248,\n",
       " 878,\n",
       " 191,\n",
       " 361,\n",
       " 242,\n",
       " 282,\n",
       " 745,\n",
       " 989,\n",
       " 143,\n",
       " 903,\n",
       " 507,\n",
       " 742,\n",
       " 1,\n",
       " 855,\n",
       " 388,\n",
       " 758,\n",
       " 438,\n",
       " 536,\n",
       " 337,\n",
       " 15,\n",
       " 659,\n",
       " 113,\n",
       " 127,\n",
       " 661,\n",
       " 833,\n",
       " 130,\n",
       " 12,\n",
       " 194,\n",
       " 212,\n",
       " 942,\n",
       " 625,\n",
       " 72,\n",
       " 557,\n",
       " 828,\n",
       " 547,\n",
       " 40,\n",
       " 954,\n",
       " 55,\n",
       " 725,\n",
       " 170,\n",
       " 475,\n",
       " 240,\n",
       " 921,\n",
       " 59,\n",
       " 86,\n",
       " 946,\n",
       " 117,\n",
       " 392,\n",
       " 221,\n",
       " 520,\n",
       " 701,\n",
       " 70,\n",
       " 270,\n",
       " 582,\n",
       " 888,\n",
       " 560,\n",
       " 494,\n",
       " 781,\n",
       " 318,\n",
       " 902,\n",
       " 979,\n",
       " 790,\n",
       " 996,\n",
       " 20,\n",
       " 503,\n",
       " 537,\n",
       " 688,\n",
       " 938,\n",
       " 748,\n",
       " 621,\n",
       " 90,\n",
       " 11,\n",
       " 540,\n",
       " 50,\n",
       " 294,\n",
       " 699,\n",
       " 188,\n",
       " 914,\n",
       " 727,\n",
       " 912,\n",
       " 449,\n",
       " 97,\n",
       " 94,\n",
       " 291,\n",
       " 101,\n",
       " 647,\n",
       " 483,\n",
       " 476,\n",
       " 719,\n",
       " 947,\n",
       " 396,\n",
       " 511,\n",
       " 648,\n",
       " 431,\n",
       " 382,\n",
       " 717,\n",
       " 272,\n",
       " 132,\n",
       " 685,\n",
       " 848,\n",
       " 271,\n",
       " 660,\n",
       " 550,\n",
       " 814,\n",
       " 184,\n",
       " 817,\n",
       " 705,\n",
       " 403,\n",
       " 998,\n",
       " 81,\n",
       " 177,\n",
       " 854,\n",
       " 450,\n",
       " 826,\n",
       " 269,\n",
       " 128,\n",
       " 562,\n",
       " 200,\n",
       " 152,\n",
       " 331,\n",
       " 816,\n",
       " 517,\n",
       " 986,\n",
       " 352,\n",
       " 766,\n",
       " 820,\n",
       " 755,\n",
       " 167,\n",
       " 865,\n",
       " 98,\n",
       " 193,\n",
       " 129,\n",
       " 348,\n",
       " 926,\n",
       " 812,\n",
       " 332,\n",
       " 472,\n",
       " 927,\n",
       " 448,\n",
       " 267,\n",
       " 963,\n",
       " 10,\n",
       " 141,\n",
       " 991,\n",
       " 393,\n",
       " 821,\n",
       " 211,\n",
       " 121,\n",
       " 26,\n",
       " 554,\n",
       " 565,\n",
       " 122,\n",
       " 277,\n",
       " 317,\n",
       " 555,\n",
       " 32,\n",
       " 754,\n",
       " 123,\n",
       " 247,\n",
       " 780,\n",
       " 645,\n",
       " 871,\n",
       " 925,\n",
       " 973,\n",
       " 83,\n",
       " 867,\n",
       " 287,\n",
       " 595,\n",
       " 335,\n",
       " 405,\n",
       " 933,\n",
       " 376,\n",
       " 839,\n",
       " 607,\n",
       " 417,\n",
       " 24,\n",
       " 135,\n",
       " 586,\n",
       " 133]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[0] for i in sorted(enumerate(-a), key=lambda x:x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_distribution[0] * (0 > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_synthetic_vec(probability_distribution, T):\n",
    "    '''\n",
    "    Args:\n",
    "        probability_distribution - a numpy array of size 1000 that represents the probability of being each label in \n",
    "                                   the training dataset\n",
    "        T : the number of highest probability that we will take into account when contructing the synthetic word embedding\n",
    "        \n",
    "        # not using# id - the id of the test image\n",
    "        # not using # dict_id_to_prob_dist_from_CNN - the dictionary that map image's id to the dictionary of probability distribution\n",
    "    '''\n",
    "    #probability_distribution = dict_id_to_prob_dist_from_CNN[image_id]\n",
    "\n",
    "    # sorted_inds = [ind[0] for ind in sorted(enumerate(-probabilities), key=lambda x:x[1])]\n",
    "    sorted_indices = [i[0] for i in sorted(enumerate(-np.array(probability_distribution)), key=lambda x:x[1])]\n",
    "    \n",
    "    highest_T_prediction = sorted_indices[:T]\n",
    "    highest_T_probability = np.array([probability_distribution[highest_T_prediction[i]] for i in range(T)])\n",
    "    word_embedding_vectors = list()\n",
    "    for training_id in highest_T_prediction:\n",
    "        synset_id = index_to_1k_id(training_id)\n",
    "        one_word_rep = get_one_word(synset_id)[0]\n",
    "        word_embedding_vectors.append(get_vec(one_word_rep))\n",
    "    word_embedding_vectors = np.array(word_embedding_vectors)\n",
    "    normalize_factor = np.sum(highest_T_probability)\n",
    "    synthetic_word_embedding_vector = np.dot(highest_T_probability/normalize_factor, word_embedding_vectors)\n",
    "    return synthetic_word_embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_prob_dist = [0.0, 5.9359947044868022e-05, 0.0, 0.0, 0.0, 0.00030838136444799602, 0.00050449889386072755, 0.00041339881136082113, 0.00024020244018174708, 0.00011523621651576832, 0.0, 0.0, 5.6997774663614109e-05, 0.00010950191062875092, 0.0, 5.8353332860860974e-05, 8.537078247172758e-05, 0.00016371006495319307, 0.00013533383025787771, 9.6306517662014812e-05, 4.8798970965435728e-05, 0.00011675487621687353, 0.0, 0.00033447783789597452, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.3882521721534431e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00024704550742171705, 5.511610652320087e-05, 0.00061703508254140615, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.1325299106538296e-05, 0.0, 0.0, 0.0, 0.0, 0.00026097087538801134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00027160046738572419, 0.0010339721338823438, 0.0, 0.00055109563982114196, 0.0, 0.0, 0.0, 0.0, 0.00035135040525346994, 0.0, 0.00015215085295494646, 0.0, 0.0, 0.0, 0.00013092003064230084, 0.0, 7.7655924542341381e-05, 0.00018479788559488952, 5.3978768846718594e-05, 0.0, 0.00019366394553799182, 0.0, 0.0, 0.00015685260586906224, 0.0, 0.00012500074808485806, 4.4697768316837028e-05, 0.0, 0.0001160772517323494, 0.0, 0.0, 6.268793367780745e-05, 0.0, 0.0, 0.00062705151503905654, 0.00038795743603259325, 0.00095065630739554763, 9.0474924945738167e-05, 0.00099362526088953018, 0.00018712821474764496, 0.00010098113125422969, 0.0, 0.0001061186267179437, 7.1551316068507731e-05, 0.00019229314057156444, 5.7340381317771971e-05, 0.00012876633263658732, 9.930397936841473e-05, 0.00013418252638075501, 5.3482141083804891e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 2.7088857677881606e-05, 0.00014696226571686566, 0.0, 0.0, 0.0, 0.0, 3.4442393371136859e-05, 5.7096844102488831e-05, 0.0, 0.0, 0.0, 0.00010888870019698516, 1.3966146980237681e-05, 0.0, 0.0, 0.0, 0.0, 0.00013430094986688346, 3.1772422516951337e-05, 0.0, 6.0304562794044614e-05, 6.3022293034009635e-05, 0.0, 0.00021076622942928225, 0.0, 8.2552789535839111e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012006429460598156, 0.0, 0.0, 0.0, 0.00021599004685413092, 0.0, 7.9270212154369801e-05, 0.0, 0.0, 0.0, 0.0, 0.00015463067393284291, 0.0, 0.0, 0.0, 0.00065351172816008329, 0.0, 8.5495245002675802e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.1019993912195787e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00010483165533514693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00020852638408541679, 0.0, 0.00014112688950262964, 0.0, 0.00011650861415546387, 0.0, 0.00022128889395389706, 0.0, 0.0, 0.0, 0.00023147434694692492, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.0898102674400434e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 6.134670547908172e-05, 0.0001492275478085503, 0.0, 0.0002259919565403834, 0.0, 6.7105058406013995e-05, 0.00021301246306393296, 0.0, 0.0, 0.0, 0.0, 0.0, 9.3959381047170609e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.2051178752444685e-05, 0.0001949161960510537, 8.0254249041900039e-05, 0.0, 0.00026387683465145528, 0.0, 0.0, 0.0, 0.0, 0.00016428154776804149, 0.0, 0.0, 0.0, 0.0, 0.0001697110419627279, 2.2908770915819332e-05, 8.3570877905003726e-05, 8.6750209447927773e-05, 0.00017913573537953198, 4.4513060856843367e-05, 9.455480903852731e-05, 0.0001215411612065509, 4.5790220610797405e-05, 0.0, 0.0, 0.0, 0.0013473816215991974, 0.0, 0.0, 0.00034969122498296201, 0.0, 0.0, 0.0, 0.0, 0.0, 9.6419920737389475e-05, 0.00013565266272053123, 8.8116707047447562e-05, 0.001448964118026197, 0.00011329482367727906, 0.00018824772268999368, 0.0, 0.00050664128502830863, 0.00010782527533592656, 0.0, 2.9131053452147171e-05, 5.0084188842447475e-05, 0.00020255257550161332, 8.9614433818496764e-05, 0.00010584003030089661, 6.6159700509160757e-05, 6.2318300479091704e-05, 0.0, 0.0, 0.00018690776778385043, 0.00038305565249174833, 0.0, 0.0, 0.00022838250151835382, 3.7115838495083153e-05, 0.0, 0.00015885742323007435, 0.00020334593136794865, 0.0, 0.00048938038526102901, 5.8708792494144291e-05, 0.0, 0.00010308229684596881, 0.00012299501395318657, 0.00033355248160660267, 0.00024292878515552729, 0.00028218890656717122, 0.00029470285517163575, 0.00023302022600546479, 0.0, 0.00017894279153551906, 3.3794614864746109e-05, 9.5371193310711533e-05, 0.0, 6.1803453718312085e-05, 3.6099518183618784e-05, 0.00016040106129366904, 0.0013978420756757259, 0.00016828365914989263, 0.00014588960038963705, 6.9333182182163e-05, 0.00058222230290994048, 0.0002312210708623752, 0.00010466093954164535, 6.1023565649520606e-05, 0.00013808328367304057, 0.00019315339159220457, 0.00020698799926321954, 6.3346895331051201e-05, 0.00034742354182526469, 9.89829859463498e-05, 8.9874061814043671e-05, 0.0, 0.0, 8.5206971562001854e-05, 0.0, 0.0002014862111536786, 0.00025324590387754142, 9.1659952886402607e-05, 0.0, 0.0, 6.3734478317201138e-05, 0.00011352026922395453, 7.5612006185110658e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00011471741163404658, 5.9042311477242038e-05, 0.0, 0.0004268205666448921, 0.0, 0.0, 0.0, 0.0, 0.0001672508951742202, 0.0, 0.00045951359788887203, 0.0, 0.19033908843994141, 0.0, 0.00024280998331960291, 0.0, 4.0111015550792217e-05, 0.00011250415263930336, 2.1107467546244152e-05, 0.00028220022795721889, 0.0001718744751997292, 6.729539018124342e-05, 0.0, 0.00017178524285554886, 0.00014936600928194821, 0.00093985325656831264, 0.0, 0.00094793632160872221, 0.00016815299750305712, 0.00020391511498019099, 1.8018808987108059e-05, 0.00017593307711649686, 0.0, 0.00020543439313769341, 0.0002066775195999071, 0.00017599281272850931, 0.0, 0.00036994699621573091, 6.8173540057614446e-05, 0.0, 0.00020055737695656717, 0.00099246413446962833, 0.001546708052046597, 0.00011432352039264515, 4.2325413232902065e-05, 0.00013576092896983027, 0.0, 0.0, 0.00012325817078817636, 7.6705953688360751e-05, 7.0154710556380451e-05, 5.8902944147121161e-05, 0.00010889430996030569, 0.0, 0.0, 0.0, 0.00016835925634950399, 0.00012172113201813772, 7.8374934673774987e-05, 8.5446859884541482e-05, 0.0002557530824560672, 0.0, 0.0, 3.9319558709394187e-05, 0.00012416573008522391, 8.1465681432746351e-05, 0.00014096299128141254, 0.00046934865531511605, 0.0, 0.00010788981307996437, 0.00069548416649922729, 0.00033153075492009521, 8.9570559794083238e-05, 0.00023033411707729101, 0.00063350651180371642, 0.00027082528686150908, 0.00068174354964867234, 0.0015379093820229173, 0.0, 7.1570153522770852e-05, 0.0, 0.00013012507406529039, 0.00014986340829636902, 7.7434473496396095e-05, 0.00037251831963658333, 3.2747680961620063e-05, 0.0, 0.00030095502734184265, 0.0, 4.3640695366775617e-05, 0.0, 0.00059289316413924098, 0.0, 0.0, 0.00031073926948010921, 0.0, 4.3926385842496529e-05, 0.00019714086374733597, 0.0, 0.00016563279496040195, 0.00094006472500041127, 0.00046814209781587124, 0.0, 0.00027495494578033686, 0.00022809102665632963, 0.00015782973787281662, 0.00018070574151352048, 5.0848993851104751e-05, 0.0, 0.0, 0.00015610206173732877, 7.5058727816212922e-05, 0.00039844101411290467, 0.0, 0.0013032042188569903, 0.0045658163726329803, 0.0, 0.0, 0.00010841310722753406, 0.00011930464097531512, 0.0, 0.00038308303919620812, 6.161183409858495e-05, 0.0, 4.2726995161501691e-05, 0.00019696203526109457, 0.00034593144664540887, 0.0, 0.0, 0.00010642505367286503, 3.6729143175762147e-05, 0.0, 9.2328336904756725e-05, 5.2831543143838644e-05, 0.0, 0.0, 0.013103589415550232, 0.00022358125715982169, 6.3509680330753326e-05, 0.00012293814506847411, 0.0, 0.0, 0.00019957960466854274, 0.0, 0.0, 0.00014964447473175824, 6.9757159508299083e-05, 7.8790530096739531e-05, 0.0, 5.8872505178442225e-05, 4.8680765758035704e-05, 0.00014094787184149027, 0.0, 0.0, 0.00021302048116922379, 0.00034812415833584964, 0.00022677892411593348, 0.0, 0.00022252870257943869, 0.0, 0.0, 0.0, 0.00041501718806102872, 0.0, 0.0, 0.00030910538043826818, 9.4587914645671844e-05, 0.0, 0.0, 0.0, 5.5708122090436518e-05, 0.00036902169813401997, 0.0, 0.0, 0.00019438947492744774, 3.7683759728679433e-05, 0.0, 0.0, 0.0, 0.00017450461746193469, 0.00016269186744466424, 0.0, 0.0, 0.0015601671766489744, 0.0, 0.00010936905164271593, 0.0, 0.0, 0.0, 0.00023735307331662625, 0.00013434354332275689, 0.00039081179420463741, 0.00027275396860204637, 0.00011201697634533048, 0.00016239169053733349, 5.1744307711487636e-05, 0.00013821233005728573, 0.0, 0.0, 0.0, 0.00077279773540794849, 0.00013173818297218531, 0.0, 0.0, 0.00020276478608138859, 0.0, 0.00028263250715099275, 7.980391092132777e-05, 2.2005071514286101e-05, 0.00091048842296004295, 0.0012353761121630669, 0.0, 0.00010620893590385094, 0.00072121067205443978, 0.00012686348054558039, 0.0, 0.0, 0.00013340712757781148, 0.0, 0.00019430569955147803, 0.0, 0.063151746988296509, 0.0002533534134272486, 0.0017925315769389272, 0.0, 0.00034102346398867667, 0.00098547921516001225, 0.00019969414279330522, 0.0, 0.00027823675191029906, 0.0, 0.00013658602256327868, 0.00021677750919479877, 0.000634213094599545, 4.7393263230333105e-05, 0.0, 0.0, 0.0001044905511662364, 0.0, 0.00025907336384989321, 0.00023627693008165807, 9.1087575128767639e-05, 0.00016528123524039984, 0.0, 0.00030207642703317106, 0.00028666268917731941, 0.00011663735494948924, 0.00015479970898013562, 0.0, 0.0, 0.00025000612367875874, 0.00069117208477109671, 0.00042557436972856522, 0.0, 0.0002703077916521579, 0.00011988592450506985, 0.00045523943845182657, 0.000152368433191441, 2.5798275601118803e-05, 0.00029855614411644638, 0.0, 0.0, 0.0, 0.00013581012899521738, 0.00020602074800990522, 0.0, 0.0, 0.0006196172907948494, 0.0013246213784441352, 9.1074842202942818e-05, 0.0001505005348008126, 0.00074922590283676982, 0.0, 0.0, 0.0, 7.0291062002070248e-05, 0.00038231717189773917, 6.9552523200400174e-05, 0.00039878141251392663, 0.00042839569505304098, 0.0014033738989382982, 0.00012421276187524199, 0.0, 0.00034184157266281545, 0.0, 0.0, 0.00011954911315115169, 0.00040156676550395787, 0.0, 9.5653012976981699e-05, 0.0012097175931558013, 0.0, 0.00015985452046152204, 0.00013729352212976664, 0.00037555641029030085, 0.00034985950333066285, 0.00032976790680550039, 0.0, 4.1474278987152502e-05, 0.0, 7.9206249210983515e-05, 4.7997946239775047e-05, 0.0, 0.0, 0.0, 0.0001560202072141692, 7.0853304350748658e-05, 0.00011995310342172161, 0.0003267792344558984, 0.0010198727250099182, 0.00022332947992254049, 7.4337694968562573e-05, 0.0, 0.0, 5.2765179134439677e-05, 0.0011175620602443814, 0.0, 0.0, 4.0211361920228228e-05, 0.00011921473196707666, 0.0, 9.3273934908211231e-05, 0.0, 0.0, 0.00010785937047330663, 0.0, 7.0804599090479314e-05, 0.00018236208416055888, 0.0, 0.0, 4.2268697143299505e-05, 0.0, 0.0, 0.0, 0.00032326026121154428, 0.0, 6.4072984969243407e-05, 0.00014494117931462824, 5.47099880350288e-05, 0.0001197561650769785, 0.0, 0.0, 0.0, 0.0003724412526935339, 0.00027317358762957156, 0.0, 0.0002080614649457857, 0.00012338148371782154, 0.00031722651328891516, 0.0, 0.0, 0.00016158775542862713, 0.0, 0.0, 0.0, 6.0056798247387633e-05, 0.0017426488921046257, 0.00014279992319643497, 6.0527021560119465e-05, 0.00022294037626124918, 0.0, 4.7440516937058419e-05, 0.0025075040757656097, 0.00016409905219916254, 7.5871357694268227e-05, 0.00017939123790711164, 0.00032161758281290531, 2.7837582820211537e-05, 0.0, 0.0, 0.0, 5.8956957218470052e-05, 0.0, 0.00018686561088543385, 0.00098743312992155552, 0.00014133060176391155, 0.00037102497299201787, 0.00025461462792009115, 0.00023573922226205468, 3.5944958653999493e-05, 0.00019102009537164122, 0.0, 0.00026344624347984791, 0.0, 0.00013814630801789463, 0.0, 0.0, 0.040721192955970764, 0.00056392780970782042, 0.00037905119825154543, 0.00063521764241158962, 0.0013690533814951777, 0.0, 2.5960376660805196e-05, 5.0690134230535477e-05, 0.00015524322225246578, 0.00011185359471710399, 0.00022653055202681571, 0.00015713737229816616, 0.0, 0.0013683615252375603, 0.0, 9.4632348918821663e-05, 0.0, 0.0, 0.0029783938080072403, 0.0, 0.0, 0.00032747321529313922, 0.0, 0.0, 0.0, 0.0, 0.00015157790039665997, 0.00028468313394114375, 0.00011909064778592438, 7.3835595685523003e-05, 0.0, 0.0, 0.021627707406878471, 0.0, 0.00059501104988157749, 0.0, 0.0, 0.0, 0.0, 0.00010670961637515575, 4.0440339944325387e-05, 0.0, 3.7014920962974429e-05, 0.0, 0.00025221719988621771, 0.00027734306058846414, 0.0, 0.0, 0.0, 8.6494117567781359e-05, 0.00031595403561368585, 0.0, 3.9083952287910506e-05, 0.00025560567155480385, 5.5667387641733512e-05, 8.4527477156370878e-05, 0.0012454951647669077, 0.0, 0.0, 5.7133991504088044e-05, 0.0030612410046160221, 0.00025087755057029426, 0.0010620503453537822, 0.00058459362480789423, 0.00074731418862938881, 0.0, 0.00013669887266587466, 0.0014333846047520638, 0.0, 0.004593702033162117, 0.00039151270175352693, 0.00022392821847461164, 0.0, 8.8666485680732876e-05, 0.0, 9.4300405180547386e-05, 0.00010683313303161412, 0.00024237108300440013, 0.0, 0.00034958150354214013, 0.0, 5.9334026445867494e-05, 7.0631343987770379e-05, 0.00026404549134895205, 0.0, 0.0001015397283481434, 0.0001934001047629863, 0.0, 6.2804734625387937e-05, 0.0, 0.00014100292173679918, 0.0, 7.7427052019629627e-05, 2.3045968191581778e-05, 0.00023686295025981963, 0.0, 0.00013174032210372388, 2.4972730898298323e-05, 0.00060290965484455228, 0.0, 0.0, 0.00011478695523692295, 0.00021186594676692039, 0.00023955378856044263, 0.0, 0.0011279782047495246, 0.00099117017816752195, 0.00013061267964076251, 0.00018885341705754399, 0.00016904028598219156, 0.00087302917381748557, 0.0016905923839658499, 0.0, 0.00022379575239028782, 0.0, 0.00023031632008496672, 0.00089380575809627771, 0.0, 0.0, 0.001726060057990253, 0.00012007338955299929, 0.00020261111785657704, 0.00015546611393801868, 0.00047033638111315668, 0.0, 0.0, 0.0, 0.0, 4.9924583436222747e-05, 6.0184254834894091e-05, 0.0, 0.0, 0.0, 0.0, 0.0003339954128023237, 0.00019536219770088792, 0.0, 0.00020657465211115777, 0.0, 0.0, 4.5316177420318127e-05, 0.00013555980694945902, 0.00025647741858847439, 0.0, 0.0, 0.0, 0.00018305497360415757, 0.0, 0.00011767732939915732, 7.9320539953187108e-05, 0.00012124872591812164, 2.4887402105377987e-05, 0.0, 0.0, 0.00017950453911907971, 0.00048840342788025737, 0.0, 0.00017025369743350893, 9.6754149126354605e-05, 2.0429244614206254e-05, 0.00014616952103096992, 0.0, 0.0, 6.6671222157310694e-05, 4.7968525905162096e-05, 8.4947823779657483e-05, 0.0, 0.0, 0.0, 0.00011135925160488114, 0.0, 0.0, 0.0, 4.3282132537569851e-05, 0.0, 0.00014065051800571382, 0.00018941501912195235, 0.00015569639799650759, 0.0001511377195129171, 0.00036275124875828624, 5.5068714573280886e-05, 0.00025726942112669349, 0.0, 0.0002071774797514081, 0.00019641328253783286, 0.00010508550622034818, 0.0, 0.00044781606993637979, 8.9888417278416455e-05, 3.20021717925556e-05, 7.9309276770800352e-05, 0.0001526114356238395, 0.0, 0.00027007731841877103, 0.00017022316751535982, 0.00011420066584832966, 0.0, 0.00024165009381249547, 0.0013018018798902631, 0.0, 0.00040509336395189166, 8.7955173512455076e-05, 0.00016316366964019835, 0.0, 0.002135994378477335, 4.9306767323287204e-05, 0.00017267507791984826, 0.00044226954923942685, 0.000566741859074682, 0.0, 6.8975241447333246e-05, 0.00010770225344458595, 0.0, 0.00033202563645318151, 0.00025149807333946228, 6.0512593336170539e-05, 7.435215957229957e-05, 0.0, 8.2108068454544991e-05, 0.0, 0.00012046709889546037, 0.00010356211714679375, 0.0, 9.115796274272725e-05, 3.9624126657145098e-05, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[0] for i in sorted(enumerate(-1 * new_prob_dist), key=lambda x:x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_prob_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = [0.0, 0.9, 0.0, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0. , -0.9, -0. , -0.1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "- np.array(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 'a'), (3, 'c'), (3, 'd'), (2, 'b')]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(4,'a'), (2,'b'), (3, 'c'), (3,'d')], reverse=True, key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for label_id in label_pool:\n",
    "    names = id_labels[label_id]\n",
    "    found_one_word = False\n",
    "    for name in names:\n",
    "        if valid_one_word(name):\n",
    "            found_one_word = True\n",
    "    if not found_one_word:\n",
    "        print \"%d %s\" % (label_id, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor(label_pool, synthetic_vector, k=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        label pool - a list of synset id from which we want to predict; each synset id must have valid-one-word\n",
    "        synthetic_vector - a numpy array representing the word embedding of an image\n",
    "        k - we will return the synset ids that have k highest similarity -> will implement this later for performance reason\n",
    "    \"\"\"\n",
    "#     highest_similarity = -10000\n",
    "    similarities = []\n",
    "    for label_id in label_pool:\n",
    "        names = id_labels[label_id]\n",
    "        nearest_label_id = None\n",
    "        nearest_label_word = None\n",
    "        highest_similarity = -1000\n",
    "        for name in names:\n",
    "            if valid_one_word(name):\n",
    "                word_embed_name = get_vec(name)\n",
    "                similarity = similarity_score(synthetic_vector, word_embed_name)\n",
    "                if similarity > highest_similarity:\n",
    "                    nearest_label_id = label_id\n",
    "                    nearest_label_word = name\n",
    "                    highest_similarity = similarity           \n",
    "        similarities.append((nearest_label_id, nearest_label_word, highest_similarity))\n",
    "    sorted_similarities = sorted(similarities, reverse=True, key=lambda x:x[2])\n",
    "#     print \"nearest_neighbor\", len(sorted_similarities[:k]), len(set(sorted_similarities[:k]))\n",
    "    return sorted_similarities[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Chang\n",
    "def nearest_neighbor(label_pool, synthetic_vector, k):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        label pool - a list of synset id from which we want to predict; each synset id must have valid-one-word\n",
    "        synthetic_vector - a numpy array representing the word embedding of an image\n",
    "        k - we will return the synset ids that have k highest similarity\n",
    "    \"\"\"\n",
    "    k_highest_similarity_labels = [(-1000,None)]*k\n",
    "    heapq.heapify(k_highest_similarity_labels)\n",
    "    for label_id in label_pool:\n",
    "        names = id_labels[label_id]\n",
    "        is_very_similar = False\n",
    "        candidate_similarity = -1000\n",
    "        for name in names:\n",
    "            if valid_one_word(name):\n",
    "                word_embed_name = get_vec(name)\n",
    "                similarity = similarity_score(synthetic_vector, word_embed_name)\n",
    "                if similarity > k_highest_similarity_labels[0][0]:\n",
    "                    is_very_similar = True\n",
    "                    candidate_similarity = max(similarity, candidate_similarity)\n",
    "        if is_very_similar:\n",
    "            heapq.heapreplace(k_highest_similarity_labels,(candidate_similarity, label_id))\n",
    "    print k_highest_similarity_labels\n",
    "    nearest_labels = list()\n",
    "    for pair in k_highest_similarity_labels:\n",
    "        nearest_labels.append(pair[1])\n",
    "    return nearest_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probability_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.32836    -0.99674     0.593625   -0.870275   -1.388815   -0.487625\n",
      "  0.738265   -0.8303      1.204402   -0.22229    -0.17535     0.8750765\n",
      " -0.892255    0.691815    0.202098    0.561855    0.21388065  0.126216\n",
      "  0.85398    -0.61261    -0.53141    -1.14974    -0.31621     0.7526\n",
      " -0.749872   -0.887915   -1.402315   -0.366905    0.287865   -0.404095\n",
      "  0.89115    -1.0442     -0.61485     1.51115     0.47518     2.67511\n",
      "  0.550975    1.046275    1.309705   -1.51706     1.182455    0.70327\n",
      " -0.713755    1.117025    1.432525   -0.77393     2.60152    -2.579455\n",
      " -0.27444    -0.235574  ]\n"
     ]
    }
   ],
   "source": [
    "# syn_vec = get_synthetic_vec(probability_distribution, 1)\n",
    "# print syn_vec\n",
    "vec = get_vec(\"buskin\") + 1.5 * get_vec(\"boot\")\n",
    "print vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n02925666']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_neighbor(label_pool, vec, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_similarity_score_vec_id(vec, label_id):\n",
    "    max_similarity = -1000\n",
    "    names = id_labels[label_id]\n",
    "    for name in names:\n",
    "        if valid_one_word(name):\n",
    "            word_embed_name = get_vec(name)\n",
    "            similarity = similarity_score(vec, word_embed_name)\n",
    "            max_similarity = max(similarity, max_similarity)\n",
    "    return max_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nearest_neighbor_with_threshold(probability_distribution, top_k, label_pool, threshold, T=10):\n",
    "\n",
    "    synthetic_vector = get_synthetic_vec(probability_distribution, T)\n",
    "    nearest_label_first_guess = nearest_neighbor(label_pool, synthetic_vector, 1)[0]\n",
    "    first_guess_id, first_guess_name, first_guess_score = nearest_label_first_guess\n",
    "    \n",
    "\n",
    "    new_prob_dist = [probability_distribution[i] * (max_similarity_score_vec_id(get_vec(first_guess_name), index_to_1k_id(i)) > threshold)\\\n",
    "        for i in range(len(probability_distribution))]\n",
    "    if sum(new_prob_dist) == 0:\n",
    "        return None\n",
    "\n",
    "    new_synthetic_vector = get_synthetic_vec(new_prob_dist, T)\n",
    "    nearest_label_final_guesses = nearest_neighbor(label_pool, new_synthetic_vector, top_k)\n",
    "#     final_guess_id = nearest_label_final_guess[2]\n",
    "#     print max_similarity_score_vec_id(new_synthetic_vector, final_guess_id)\n",
    "#     return [x[0] for x in nearest_label_final_guesses]\n",
    "    return nearest_label_final_guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity_score(this, that, normalized = True, euclidean=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        this - a numpy array representing the first vector \n",
    "        that - a numpy array representing the second vector \n",
    "        normalized - indicates if the score needs to be normalized\n",
    "    \"\"\"\n",
    "    if euclidean:\n",
    "        score = - np.linalg.norm(this - that)\n",
    "        return score\n",
    "    if normalized:\n",
    "        score = np.dot(this, that)/(np.linalg.norm(this)*np.linalg.norm(that))\n",
    "    else:\n",
    "        score = np.dot(this, that)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeroshot",
   "language": "python",
   "name": "zeroshot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
